{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ДЗ34 PRO Власов АЛ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOMCzkmbYMAn"
      },
      "source": [
        "# Установка и настройка Pyspark\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/sOTh6klME_M?t=4631"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_g46d6C8a05",
        "outputId": "15079444-b897-4827-9da9-1caac5b970aa"
      },
      "source": [
        "!wget http://mirror.klaus-uwe.me/apache/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-01 18:43:01--  http://mirror.klaus-uwe.me/apache/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n",
            "Resolving mirror.klaus-uwe.me (mirror.klaus-uwe.me)... 94.130.201.139, 2a01:4f8:13b:228c::2\n",
            "Connecting to mirror.klaus-uwe.me (mirror.klaus-uwe.me)|94.130.201.139|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 233333392 (223M) [application/octet-stream]\n",
            "Saving to: ‘spark-2.4.7-bin-hadoop2.7.tgz’\n",
            "\n",
            "spark-2.4.7-bin-had 100%[===================>] 222.52M  30.0MB/s    in 8.0s    \n",
            "\n",
            "2021-02-01 18:43:10 (27.8 MB/s) - ‘spark-2.4.7-bin-hadoop2.7.tgz’ saved [233333392/233333392]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8_4iq5CXZKt"
      },
      "source": [
        "# !tar xf spark-2.4.7-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDjPFtLuWJ5o",
        "outputId": "7e5a0a2c-0e3f-47f5-c718-44303da14ac1"
      },
      "source": [
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_282\"\r\n",
            "OpenJDK Runtime Environment (build 1.8.0_282-8u282-b08-0ubuntu1~20.04-b08)\r\n",
            "OpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHkiu5KJylhQ",
        "scrolled": true,
        "outputId": "68653ae1-a790-4d69-bedf-60c9843f5382"
      },
      "source": [
        "!ls /usr/lib/jvm/java-8-openjdk-amd64"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ASSEMBLY_EXCEPTION  docs     jre  man\t   THIRD_PARTY_README\r\n",
            "bin\t\t    include  lib  src.zip\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5k-tcM2YMAv"
      },
      "source": [
        "import os\n",
        "# Задаем окружение\n",
        "# Указываем переменные окружения для findspark\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"spark-2.4.7-bin-hadoop2.7\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4emDGexcYMA0"
      },
      "source": [
        "Инциализируем pyspark из директории с библиотекой"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inUUobPGYMA2"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "renXuoxkYMA6"
      },
      "source": [
        "Запускаем Spark-сессию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9GpWZ09YMA8"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master('local[*]').getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXTgSnqvMOIJ"
      },
      "source": [
        "# PRO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oDVC0DDMOIJ"
      },
      "source": [
        "Взял примеры классификации из документации.\n",
        "Первый классифкиатор разбил по ячейкам с выводом промежуточных значений - для собственного понимания того,\n",
        "как обрабатываются данные\n",
        "\n",
        "Оставшиеся модели аналогичны, поэтому выполнял код срзу в одной ячейке."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xklQ-k_oMOIJ"
      },
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier, MultilayerPerceptronClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer, IndexToString\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmJX2cgQMOIJ"
      },
      "source": [
        "## GBTClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-8wMWXuMOIK"
      },
      "source": [
        "# Load and parse the data file, converting it to a DataFrame.\n",
        "data = spark.read.format(\"libsvm\").load(\"sample_libsvm_data.txt\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "CNpgmvYrMOIK",
        "outputId": "722261e4-280f-423d-a8d6-e68f4e37c1e5"
      },
      "source": [
        "data.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  0.0|(692,[127,128,129...|\n",
            "|  1.0|(692,[158,159,160...|\n",
            "|  1.0|(692,[124,125,126...|\n",
            "|  1.0|(692,[152,153,154...|\n",
            "|  1.0|(692,[151,152,153...|\n",
            "|  0.0|(692,[129,130,131...|\n",
            "|  1.0|(692,[158,159,160...|\n",
            "|  1.0|(692,[99,100,101,...|\n",
            "|  0.0|(692,[154,155,156...|\n",
            "|  0.0|(692,[127,128,129...|\n",
            "|  1.0|(692,[154,155,156...|\n",
            "|  0.0|(692,[153,154,155...|\n",
            "|  0.0|(692,[151,152,153...|\n",
            "|  1.0|(692,[129,130,131...|\n",
            "|  0.0|(692,[154,155,156...|\n",
            "|  1.0|(692,[150,151,152...|\n",
            "|  0.0|(692,[124,125,126...|\n",
            "|  0.0|(692,[152,153,154...|\n",
            "|  1.0|(692,[97,98,99,12...|\n",
            "|  1.0|(692,[124,125,126...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw9MULo9MOIK"
      },
      "source": [
        "\n",
        "# Index labels, adding metadata to the label column.\n",
        "# Fit on whole dataset to include all labels in index.\n",
        "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFym9W0eMOIK"
      },
      "source": [
        "\n",
        "# Automatically identify categorical features, and index them.\n",
        "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "featureIndexer =\\\n",
        "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXYUo3wlMOIK",
        "outputId": "1b0a4203-e812-4235-d0f5-bcc505c4e2a9"
      },
      "source": [
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "print(trainingData.show())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  0.0|(692,[95,96,97,12...|\n",
            "|  0.0|(692,[100,101,102...|\n",
            "|  0.0|(692,[121,122,123...|\n",
            "|  0.0|(692,[122,123,124...|\n",
            "|  0.0|(692,[122,123,148...|\n",
            "|  0.0|(692,[123,124,125...|\n",
            "|  0.0|(692,[123,124,125...|\n",
            "|  0.0|(692,[124,125,126...|\n",
            "|  0.0|(692,[124,125,126...|\n",
            "|  0.0|(692,[124,125,126...|\n",
            "|  0.0|(692,[124,125,126...|\n",
            "|  0.0|(692,[125,126,127...|\n",
            "|  0.0|(692,[126,127,128...|\n",
            "|  0.0|(692,[126,127,128...|\n",
            "|  0.0|(692,[126,127,128...|\n",
            "|  0.0|(692,[126,127,128...|\n",
            "|  0.0|(692,[126,127,128...|\n",
            "|  0.0|(692,[126,127,128...|\n",
            "|  0.0|(692,[127,128,129...|\n",
            "|  0.0|(692,[127,128,129...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8B24qd9MOIL"
      },
      "source": [
        "# Train a GBT model.\n",
        "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laDv7SsWMOIL"
      },
      "source": [
        "# Chain indexers and GBT in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
        "\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "# Make predictions.\n",
        "predictions = model.transform(testData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "HzoxcivIMOIL",
        "outputId": "100d4ae3-e9fb-4a56-d738-410569d06ba7"
      },
      "source": [
        "predictions.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+------------+--------------------+--------------------+--------------------+----------+\n",
            "|label|            features|indexedLabel|     indexedFeatures|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+------------+--------------------+--------------------+--------------------+----------+\n",
            "|  0.0|(692,[98,99,100,1...|         1.0|(692,[98,99,100,1...|[-1.2448727431634...|[0.07658019351661...|       1.0|\n",
            "|  0.0|(692,[123,124,125...|         1.0|(692,[123,124,125...|[-1.3259026792203...|[0.06587782434721...|       1.0|\n",
            "|  0.0|(692,[124,125,126...|         1.0|(692,[124,125,126...|[-1.3259026792203...|[0.06587782434721...|       1.0|\n",
            "|  0.0|(692,[124,125,126...|         1.0|(692,[124,125,126...|[-1.3259026792203...|[0.06587782434721...|       1.0|\n",
            "|  0.0|(692,[126,127,128...|         1.0|(692,[126,127,128...|[-1.2505858528532...|[0.07577607990715...|       1.0|\n",
            "|  0.0|(692,[126,127,128...|         1.0|(692,[126,127,128...|[-1.2505858528532...|[0.07577607990715...|       1.0|\n",
            "|  0.0|(692,[234,235,237...|         1.0|(692,[234,235,237...|[-1.0222283433076...|[0.11461370171976...|       1.0|\n",
            "|  1.0|(692,[97,98,99,12...|         0.0|(692,[97,98,99,12...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
            "|  1.0|(692,[100,101,102...|         0.0|(692,[100,101,102...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
            "|  1.0|(692,[123,124,125...|         0.0|(692,[123,124,125...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
            "|  1.0|(692,[124,125,126...|         0.0|(692,[124,125,126...|[1.25556972130413...|[0.92491905605876...|       0.0|\n",
            "|  1.0|(692,[124,125,126...|         0.0|(692,[124,125,126...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
            "|  1.0|(692,[125,126,127...|         0.0|(692,[125,126,127...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
            "|  1.0|(692,[127,128,129...|         0.0|(692,[127,128,129...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
            "|  1.0|(692,[127,128,129...|         0.0|(692,[127,128,129...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
            "|  1.0|(692,[127,128,129...|         0.0|(692,[127,128,129...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
            "|  1.0|(692,[127,128,154...|         0.0|(692,[127,128,154...|[1.25556972130413...|[0.92491905605876...|       0.0|\n",
            "|  1.0|(692,[128,129,130...|         0.0|(692,[128,129,130...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
            "|  1.0|(692,[128,129,130...|         0.0|(692,[128,129,130...|[1.32590267922033...|[0.93412217565278...|       0.0|\n",
            "|  1.0|(692,[129,130,131...|         0.0|(692,[129,130,131...|[-1.1629471366447...|[0.08900099356639...|       1.0|\n",
            "+-----+--------------------+------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5arZwyuMOIL",
        "outputId": "3874a0ee-1e00-4ef1-a02b-795b90b1bd19"
      },
      "source": [
        "\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(30)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
        "\n",
        "gbtModel = model.stages[2]\n",
        "print(gbtModel)  # summary only"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+------------+--------------------+\n",
            "|prediction|indexedLabel|            features|\n",
            "+----------+------------+--------------------+\n",
            "|       1.0|         1.0|(692,[98,99,100,1...|\n",
            "|       1.0|         1.0|(692,[123,124,125...|\n",
            "|       1.0|         1.0|(692,[124,125,126...|\n",
            "|       1.0|         1.0|(692,[124,125,126...|\n",
            "|       1.0|         1.0|(692,[126,127,128...|\n",
            "|       1.0|         1.0|(692,[126,127,128...|\n",
            "|       1.0|         1.0|(692,[234,235,237...|\n",
            "|       0.0|         0.0|(692,[97,98,99,12...|\n",
            "|       0.0|         0.0|(692,[100,101,102...|\n",
            "|       0.0|         0.0|(692,[123,124,125...|\n",
            "|       0.0|         0.0|(692,[124,125,126...|\n",
            "|       0.0|         0.0|(692,[124,125,126...|\n",
            "|       0.0|         0.0|(692,[125,126,127...|\n",
            "|       0.0|         0.0|(692,[127,128,129...|\n",
            "|       0.0|         0.0|(692,[127,128,129...|\n",
            "|       0.0|         0.0|(692,[127,128,129...|\n",
            "|       0.0|         0.0|(692,[127,128,154...|\n",
            "|       0.0|         0.0|(692,[128,129,130...|\n",
            "|       0.0|         0.0|(692,[128,129,130...|\n",
            "|       1.0|         0.0|(692,[129,130,131...|\n",
            "|       0.0|         0.0|(692,[129,130,131...|\n",
            "|       0.0|         0.0|(692,[129,130,131...|\n",
            "|       0.0|         0.0|(692,[129,130,131...|\n",
            "|       0.0|         0.0|(692,[129,130,131...|\n",
            "|       0.0|         0.0|(692,[129,130,131...|\n",
            "|       0.0|         0.0|(692,[130,131,132...|\n",
            "|       0.0|         0.0|(692,[155,156,157...|\n",
            "|       0.0|         0.0|(692,[155,156,157...|\n",
            "+----------+------------+--------------------+\n",
            "\n",
            "Test Error = 0.0357143\n",
            "GBTClassificationModel (uid=GBTClassifier_efffa2a5a2c9) with 10 trees\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUG2NDPFMOIL"
      },
      "source": [
        "## ПРО 2. Другие метрики оценки модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMZvCA9MMOIM"
      },
      "source": [
        "### F-measure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zV2-75wgMOIN",
        "outputId": "4a630412-4b8d-46f2-866a-3871600d971c"
      },
      "source": [
        "evaluator2 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "accuracy2 = evaluator2.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Error = 0.0349593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08UpUVJQMOIN"
      },
      "source": [
        "### weightedPrecision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoaRDYsoMOIN",
        "outputId": "8c71d5d3-45a8-4dee-ad2e-794bfddb083c"
      },
      "source": [
        "evaluator3 = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
        "accuracy3 = evaluator3.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Error = 0.03125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri7MHfatMOIN"
      },
      "source": [
        "## RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THD_8Uy2MOIO",
        "outputId": "6dd7082e-d991-474d-b3cb-da5727bb7ef5"
      },
      "source": [
        "# Load and parse the data file, converting it to a DataFrame.\n",
        "data = spark.read.format(\"libsvm\").load(\"sample_libsvm_data.txt\")\n",
        "\n",
        "# Index labels, adding metadata to the label column.\n",
        "# Fit on whole dataset to include all labels in index.\n",
        "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
        "\n",
        "# Automatically identify categorical features, and index them.\n",
        "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
        "featureIndexer =\\\n",
        "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
        "\n",
        "# Split the data into training and test sets (30% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Train a RandomForest model.\n",
        "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
        "\n",
        "# Convert indexed labels back to original labels.\n",
        "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
        "                               labels=labelIndexer.labels)\n",
        "\n",
        "# Chain indexers and forest in a Pipeline\n",
        "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
        "\n",
        "# Train model.  This also runs the indexers.\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "# Make predictions.\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"predictedLabel\", \"label\", \"features\").show(30)\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
        "\n",
        "rfModel = model.stages[2]\n",
        "print(rfModel)  # summary only"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-----+--------------------+\n",
            "|predictedLabel|label|            features|\n",
            "+--------------+-----+--------------------+\n",
            "|           0.0|  0.0|(692,[123,124,125...|\n",
            "|           0.0|  0.0|(692,[124,125,126...|\n",
            "|           0.0|  0.0|(692,[125,126,127...|\n",
            "|           0.0|  0.0|(692,[126,127,128...|\n",
            "|           0.0|  0.0|(692,[126,127,128...|\n",
            "|           0.0|  0.0|(692,[126,127,128...|\n",
            "|           0.0|  0.0|(692,[126,127,128...|\n",
            "|           0.0|  0.0|(692,[152,153,154...|\n",
            "|           0.0|  0.0|(692,[154,155,156...|\n",
            "|           0.0|  0.0|(692,[154,155,156...|\n",
            "|           1.0|  1.0|(692,[100,101,102...|\n",
            "|           1.0|  1.0|(692,[119,120,121...|\n",
            "|           1.0|  1.0|(692,[123,124,125...|\n",
            "|           1.0|  1.0|(692,[123,124,125...|\n",
            "|           1.0|  1.0|(692,[124,125,126...|\n",
            "|           1.0|  1.0|(692,[124,125,126...|\n",
            "|           1.0|  1.0|(692,[124,125,126...|\n",
            "|           1.0|  1.0|(692,[125,126,153...|\n",
            "|           1.0|  1.0|(692,[125,126,153...|\n",
            "|           1.0|  1.0|(692,[126,127,128...|\n",
            "|           1.0|  1.0|(692,[127,128,129...|\n",
            "|           1.0|  1.0|(692,[128,129,130...|\n",
            "|           1.0|  1.0|(692,[128,129,130...|\n",
            "|           1.0|  1.0|(692,[128,129,130...|\n",
            "|           1.0|  1.0|(692,[128,129,155...|\n",
            "|           1.0|  1.0|(692,[129,130,131...|\n",
            "|           1.0|  1.0|(692,[129,130,131...|\n",
            "|           1.0|  1.0|(692,[129,130,131...|\n",
            "|           1.0|  1.0|(692,[150,151,152...|\n",
            "|           1.0|  1.0|(692,[152,153,154...|\n",
            "+--------------+-----+--------------------+\n",
            "only showing top 30 rows\n",
            "\n",
            "Test Error = 0\n",
            "RandomForestClassificationModel (uid=RandomForestClassifier_362f3052c369) with 10 trees\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdyzWqx0MOIO"
      },
      "source": [
        "## MultilayerPerceptronClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZm0iJj3MOIO",
        "outputId": "e0479846-6303-46ba-985c-cb4bbea50c2b"
      },
      "source": [
        "# Load training data\n",
        "data = spark.read.format(\"libsvm\")\\\n",
        "    .load(\"sample_multiclass_classification_data.txt\")\n",
        "\n",
        "# Split the data into train and test\n",
        "splits = data.randomSplit([0.6, 0.4], 1234)\n",
        "train = splits[0]\n",
        "test = splits[1]\n",
        "\n",
        "# specify layers for the neural network:\n",
        "# input layer of size 4 (features), two intermediate of size 5 and 4\n",
        "# and output of size 3 (classes)\n",
        "layers = [4, 5, 4, 3]\n",
        "\n",
        "# create the trainer and set its parameters\n",
        "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
        "\n",
        "# train the model\n",
        "model = trainer.fit(train)\n",
        "\n",
        "# compute accuracy on the test set\n",
        "result = model.transform(test)\n",
        "predictionAndLabels = result.select(\"prediction\", \"label\")\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set accuracy = 0.9019607843137255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr2yMOaAMOIO",
        "outputId": "c936d310-24fa-47ef-e5cd-5c1cf85927f1"
      },
      "source": [
        "result.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|label|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "|  0.0|(4,[0,1,2,3],[-0....|[-29.588369001638...|[2.63020383878084...|       2.0|\n",
            "|  0.0|(4,[0,1,2,3],[-0....|[125.657894478296...|[1.0,1.4484875476...|       0.0|\n",
            "|  0.0|(4,[0,1,2,3],[-0....|[126.190155254739...|[1.0,5.1578089761...|       0.0|\n",
            "|  0.0|(4,[0,1,2,3],[-0....|[-26.984478255346...|[4.23003198458660...|       2.0|\n",
            "|  0.0|(4,[0,1,2,3],[-0....|[-29.588369001638...|[2.63020383878084...|       2.0|\n",
            "|  0.0|(4,[0,1,2,3],[-1....|[-29.588368732563...|[2.63020459374897...|       2.0|\n",
            "|  0.0|(4,[0,1,2,3],[0.1...|[126.190175711705...|[1.0,5.1572549882...|       0.0|\n",
            "|  0.0|(4,[0,1,2,3],[0.2...|[126.190175994586...|[1.0,5.1572473280...|       0.0|\n",
            "|  0.0|(4,[0,1,2,3],[0.3...|[126.190175994586...|[1.0,5.1572473280...|       0.0|\n",
            "|  0.0|(4,[0,1,2,3],[0.3...|[126.190175994586...|[1.0,5.1572473280...|       0.0|\n",
            "|  0.0|(4,[0,1,2,3],[0.3...|[126.190175994586...|[1.0,5.1572473280...|       0.0|\n",
            "|  0.0|(4,[0,1,2,3],[0.4...|[126.190175994586...|[1.0,5.1572473280...|       0.0|\n",
            "|  0.0|(4,[0,1,2,3],[0.5...|[126.190175994586...|[1.0,5.1572473280...|       0.0|\n",
            "|  0.0|(4,[0,1,2,3],[0.7...|[126.190175994586...|[1.0,5.1572473280...|       0.0|\n",
            "|  0.0|(4,[0,1,2,3],[0.8...|[126.190175994586...|[1.0,5.1572473280...|       0.0|\n",
            "|  0.0|(4,[0,1,2,3],[1.0...|[126.190175994592...|[1.0,5.1572473278...|       0.0|\n",
            "|  0.0|(4,[0,2,3],[0.166...|[126.190175994583...|[1.0,5.1572473280...|       0.0|\n",
            "|  0.0|(4,[0,2,3],[0.388...|[126.190175994586...|[1.0,5.1572473280...|       0.0|\n",
            "|  1.0|(4,[0,1,2,3],[-0....|[-122.71364090590...|[1.47439846164393...|       1.0|\n",
            "|  1.0|(4,[0,1,2,3],[-0....|[-122.71364090590...|[1.47439846164393...|       1.0|\n",
            "+-----+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}